{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Ciência dos Dados\n",
    "- *Objetivo:* Prever uma variável principal em função de demais outras\n",
    "variáveis que podem influenciar em seu comportamento.\n",
    "- *Projeto feito por:* Beatriz Borges Zackiewicz, Cameron Swan, Felipe Fuchs, Renato Passarelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas e Diretório de Trabalho\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introdução\n",
    "A época do mês de Janeiro é muito movimentada de fluxo de pessoas em todos os países, devido as festas de fim de ano e período de férias. Assim, o fluxo de voos em aeroportos é aumentado, uma vez que aviões são um dos principais meios de transportes nesse período. Nos Estados Unidos não poderia ser diferente. \n",
    "Nosso objetivo com esse estudo é de prever: um voo americano período de Janeiro será cancelado ou não? \n",
    "\n",
    "### O Dataset\n",
    "Para esse estudo, utilizamos um dataset com as principais informações sobre voos nos aeroportos americanos de janeiro de 2019 e 2020.\n",
    "- *Dataset File:* \"Jan_2019_ontime.csv\" e \"Jan_2020_ontime.csv\"\n",
    "- *Dataset Author:* DIVYANSH AGRAWAL\n",
    "- *Link para o Dataset:* https://www.kaggle.com/datasets/divyansh22/flight-delay-prediction\n",
    "\n",
    "#### Informações do Dataset\n",
    "- **`DAY_OF_MONTH:`** Dia do Mês de Janeiro do voo\n",
    "- **`DAY_OF_WEEK:`** Dia da semana de Janeiro no voo\n",
    "- **`OP_UNIQUE_CARRIER:`** Código único da companhia aérea (usado para a suas coligadas)\n",
    "- **`OP_CARRIER_AIRLINE_ID:`** Número de identificação dado pela US DOT para identificar a linha aérea.\n",
    "- **`OP_CARRIER:`** Código de identificação dado pela IATA e comumente usado para identificar a linha áerea. Como o mesmo código foi usado para aviões diferentes com o tempo, nem sempre é único.\n",
    "- **`TAIL_NUM:`** Número de cauda\n",
    "- **`OP_CARRIER_FL_NUM:`** Número do voo\n",
    "- **`ORIGIN_AIRPORT_ID`** Identificação do aeroporto de origem do voo. O número de identificação é dado pela US DOT para identificar um aeroporto. \n",
    "- **`ORIGIN_AIRPORT_SEQ_ID:`** Aeroporto de origem, ID de sequencia. Número de identificação dado pela US DOT para identificar o aeroporto num determinado itinerario.\n",
    "- **`ORIGIN:`** Aeroporto de origem\n",
    "- **`DEST_AIRPORT_ID:`** Identificação do aeroporto de destino. Número de identificação dado pela US DOT para identificar o aeroporto.\n",
    "- **`DEST_AIRPORT_SEQ_ID:`** Aeroporto de destino, ID de sequencia. Número de identificação dado pela US DOT para identificar o aeroporto num determinado itinerario.\n",
    "- **`DEST:`** Aeroporto de destino\n",
    "- **`DEP_TIME:`** Hórario de saída do voo\n",
    "- **`DEP_DEL15:`** Se houve atraso de 15 minutos na saída: 0.0 = não / 1.0 = sim\n",
    "- **`DEP_TIME_BLK:`** Bloco de horários de saída, intervalo de 1 hora\n",
    "- **`ARR_TIME:`** Horário de chegada do voo\n",
    "- **`ARR_DEL15:`** Se houve atraso de 15 minutos na chegada: 0.0 = não / 1.0 = sim\n",
    "- **`CANCELLED:`** Se foi canelado: 0.0 = não / 1.0 = sim\n",
    "- **`DIVERTED:`** Se foi desviado: 0.0 = não / 1.0 = sim\n",
    "- **`DISTANCE:`** Distancia percorrida\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nosso Target e Features\n",
    "\n",
    "Prever: Se um voo americano em Janeiro vai ser cancelado ou não.\n",
    "\n",
    "**`Target:`** Cancelado ou não --> coluna CANCELLED do dataset\n",
    "\n",
    "**`Features:`** \n",
    "- Cia Aérea (OP_CARRIER)\n",
    "- Origem (ORIGIN) \n",
    "- Destino (DEST)\n",
    "- Atrasado (DEP_DEL15)\n",
    "- Distância (DISTANCE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Modelo e Técnicas de Predição\n",
    "No nosso estudo usamos: \n",
    "- Teste Qui-Quadrado de Pearson\n",
    "- Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Importando o DataSet\n",
    "Importando e Juntando os Datasets dos dois anos em um só, filtrando apenas as features e o target de interesse para o estudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTRANDO APENAS DADOS INTERESSANTES\n",
    "dados_2019 = pd.read_csv('Jan_2019_ontime.csv', sep=',')\n",
    "# manter: OP_CARRIER, ORIGIN, DESTINATION, CANCELLED, DIVERTED, DISTANCE\n",
    "Novos_dados_2019 = dados_2019.loc[:,['OP_CARRIER','ORIGIN', 'DEST','CANCELLED','DISTANCE']]\n",
    "Novos_dados_2019['Ano'] = 2019\n",
    "dados_2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2020 = pd.read_csv('Jan_2020_ontime.csv')\n",
    "# manter: OP_CARRIER, ORIGIN, DESTINATION, CANCELLED, DIVERTED, DISTANCE\n",
    "Novos_dados_2020 = dados_2020.loc[:,['OP_CARRIER','ORIGIN', 'DEST','CANCELLED','DISTANCE']]\n",
    "Novos_dados_2020['Ano'] = 2020\n",
    "Novos_dados_2020.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_base  = pd.merge(Novos_dados_2020 , Novos_dados_2019, how = 'outer') # JUNTANDO AS DUAS BASES DE DADOS\n",
    "\n",
    "General_base ['OP_CARRIER'] = General_base ['OP_CARRIER'].astype('category')\n",
    "General_base ['ORIGIN'] = General_base ['ORIGIN'].astype('category')\n",
    "General_base ['DEST'] = General_base ['DEST'].astype('category')\n",
    "General_base ['CANCELLED'] = General_base ['CANCELLED'].astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comparador = pd.read_csv('Pasta1.csv')\n",
    "print(Comparador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_base ['OP_CARRIER'].cat.categories = [' Endeavor','American Airlines Cargo','Alaska Airlines','JetBlue','Delta Air Lines','Atlatic Southeast Airlines','Frontier Flight','Allegiant Air','Hawaiian Airlines','Envoy Air','Spirit Airlines','Comair Delta Connection','SkyWest Airlines','United Airlines Cargo','Southwest Airlines','Mesa Airlines','Midwest Airlines']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_gerais_00 = General_base \n",
    "Dados_gerais_00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fracionando o Dataset\n",
    "Uma vez que o nosso Dataset final (unindo 2019 e 2020) possui mais de 1 milhão de voos, precisamos fracionar aleatóriamente ele para podermos rodar todas as iterações necessárias sem quebrar o programa. \n",
    "\n",
    "Fracionamos o DataSet em 10%\n",
    "\n",
    "Além disso também precisamos eliminar os valores nulos do Dataset para não atrapalhar na análise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_gerais_00 = General_base \n",
    "Dados_gerais = Dados_gerais_00.sample(frac = 0.01)\n",
    "rest_Dados_gerais = Dados_gerais_00.drop(Dados_gerais.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_gerais.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECANDO SE TEMOS VALORES NULOS\n",
    "Cancelados = Dados_gerais[Dados_gerais['CANCELLED'] == 1.0]\n",
    "Nao_cancelados = Dados_gerais[Dados_gerais['CANCELLED'] == 0.0]\n",
    "\n",
    "print(Cancelados.isnull().sum())\n",
    "print(len(Cancelados))\n",
    "print(Nao_cancelados.isnull().sum())\n",
    "print(len(Nao_cancelados))\n",
    "# --> está certo, resultados esperados pois voos cancelados não atrasam e não cancelados podem ainda assim atrasar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nosso Target --> qualitativo (SIM/NÃO --> 1.0/0.0 --> CANCELADO/NÃO CANCELADO), por isso temos que \n",
    "# Estudar as relações com base em gráficos de QualitativasXQuantitativas e QualitativasXQualitativas\n",
    "\n",
    "# CANCELADOS X DISTANCIA --> único caso qualixquant do nosso df\n",
    "display(Dados_gerais.groupby(by= [Dados_gerais.CANCELLED]).DISTANCE.describe().round(3))\n",
    "display(Cancelados.groupby(by= [Cancelados.CANCELLED == 1.0]).DISTANCE.describe().round(3))\n",
    "display(Nao_cancelados.groupby(by= [Nao_cancelados.CANCELLED == 1.0]).DISTANCE.describe().round(3))\n",
    "\n",
    "amplitude = Dados_gerais.DISTANCE.max()-Dados_gerais.DISTANCE.min()\n",
    "amplitude_faixa= amplitude/ 10\n",
    "faixa= np.arange(30, 5100.0, amplitude_faixa )\n",
    "\n",
    "amplitude_cancelados = Cancelados.DISTANCE.max()-Cancelados.DISTANCE.min()\n",
    "amplitude_faixa_cancelados = amplitude_cancelados / 10\n",
    "faixa_canc = np.arange(30, 4480.0, amplitude_faixa_cancelados )\n",
    "\n",
    "amplitude_nao_cancelados = Nao_cancelados.DISTANCE.max()-Nao_cancelados.DISTANCE.min()\n",
    "amplitude_faixa_nao_cancelados = amplitude_nao_cancelados / 10\n",
    "faixa_nao_canc = np.arange(30, 5100.0, amplitude_faixa_nao_cancelados )\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "# GRÁFICO DA DISTÂNCIA POR VOO\n",
    "plt.subplot(131)\n",
    "plt.hist(Dados_gerais.DISTANCE, bins=faixa_canc, color='darkcyan', edgecolor='white')\n",
    "plt.title('Contagem da Distância dos Voos')\n",
    "plt.ylabel('Frequência absoluta')\n",
    "# GRÁFICO CANCELADOS\n",
    "plt.subplot(132)\n",
    "plt.hist(Cancelados.DISTANCE, bins=faixa_canc, color='darkcyan', edgecolor='white')\n",
    "plt.title('Contagem da Distância dos Voos Cancelados')\n",
    "plt.ylabel('Frequência absoluta')\n",
    "# GRÁFICO NÃO CANCELADOS\n",
    "plt.subplot(133)\n",
    "plt.hist(Nao_cancelados.DISTANCE, bins=faixa_nao_canc, color='darkcyan', edgecolor='white')\n",
    "plt.title('Contagem da Distância dos Voos NÃO Cancelados')\n",
    "plt.ylabel('Frequência absoluta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRUZAMENTO DE QUALITATIVAS CM QUALITATIVAS\n",
    "# FAZER TABELA DE FREQUENCIAS + GRÁFICOS DE BARRA\n",
    "# PLOTAR UM AO LADO DO OUTRO SE POSSÍVEL\n",
    "# Cia X Cancelados\n",
    "cia_canc = pd.crosstab(Dados_gerais['OP_CARRIER'],Dados_gerais['CANCELLED'], normalize='index', margins=True).round(3)*100\n",
    "#cia_canc__ordenado = cia_canc.sort_values(by=0.0)\n",
    "print(display(cia_canc))\n",
    "cia_canc.plot.bar()\n",
    "plt.title('Cia Aérea X Status dos Voos')\n",
    "plt.ylabel('Total Voos')\n",
    "plt.xlabel('Cia Aérea')\n",
    "plt.legend(loc='center')\n",
    "plt.legend(['Não Cancelado', 'Cancelado'],bbox_to_anchor=(1.05, 0.95)); # Coloca legenda para fora da janela gráfica\n",
    "plt.show()\n",
    "\n",
    "# Destino X Cancelados\n",
    "dest_canc = pd.crosstab(Dados_gerais['DEST'], Dados_gerais['CANCELLED'], normalize='index',margins=True).round(3)*100\n",
    "#dest_canc_ordenado = dest_canc.sort_values(0.0)\n",
    "print(display(dest_canc))\n",
    "dest_canc.plot.bar()\n",
    "plt.title('Destinos X Status dos Voos')\n",
    "plt.ylabel('Total Voos')\n",
    "plt.xlabel('Destino')\n",
    "plt.legend(loc='center')\n",
    "plt.legend(['Não Cancelado', 'Cancelado'],bbox_to_anchor=(1.05, 0.95)); # Coloca legenda para fora da janela gráfica\n",
    "plt.show()\n",
    "\n",
    "# Origem X Cancelados\n",
    "org_canc = pd.crosstab(Dados_gerais['ORIGIN'], Dados_gerais['CANCELLED'], normalize='index',margins=True).round(3)*100\n",
    "#org_canc_ordenado = org_canc.sort_values(0.0)\n",
    "print(display(org_canc))\n",
    "org_canc.plot.bar()\n",
    "plt.title('Origens X Status dos Voos')\n",
    "plt.ylabel('Total Voos')\n",
    "plt.xlabel('Origem')\n",
    "plt.legend(loc='center')\n",
    "plt.legend(['Não Cancelado', 'Cancelado'],bbox_to_anchor=(1.05, 0.95)); # Coloca legenda para fora da janela gráfica\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando o Teste Qui-Quadrado de Pearson \n",
    "Apesar de plotados os gráficos de relação entre o Target e cada feature, não conseguimos observar alguma relação clara, uma vez que nas features de Origens e Destino, temos muitas classificações, fazendo com que a visualização do gráfico não fique tão clara. \n",
    "\n",
    "**`O Método:`** o Método do Teste Qui-Quadrado de Pearson é um teste que valida a dependência entre variáveis Categóricas, possuindo o objetivo final de verificar se duas variáveis são dependentes ou não entre sí. \n",
    "Ele consiste em estabeler uma Hipótese Nula (H0) = Não há dependência entre as variáveis, e para verificar essa hípose ele usa ou o valor-p ou o valor Qui-Quadrado.\n",
    "Aqui escolhemos analisar pelo valor-p, uma vez que já estudamos ele no curso.\n",
    "\n",
    "**`Aplicação:`**  \n",
    "O valor-p é a probabilidade de ter uma diferença entre as variáveis maior do que a que se foi observada para a H0.\n",
    "Estabelecemos um valor de signifiância (alfa) = 5%, ou seja, ele descreve a probabilidade de rejeitar H0 erroneamente quando for verdadeiro. Assim, se o valor-p for maior do que o alfa, devemos aceitar H0, concluindo pela independência entre as duas variáveis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTE QUI-QUADRADO DE PEARSON - teste de independência entre variáveis ​​categóricas\n",
    "# adotando alfa de significancia = 5% (0.05)\n",
    "from scipy.stats import chi2_contingency\n",
    "alpha = 0.05\n",
    "\n",
    "# Dependendia do status do voo X CIA AREA \n",
    "stat, pcia, dof, expected = chi2_contingency(cia_canc)\n",
    "print(\"valor-p cia aérea é \" + str(pcia))\n",
    "if pcia <= alpha:\n",
    "    print('Cancelamento e CIA aérea são DEPENDENTES')\n",
    "else:\n",
    "    print('Cancelamento e CIA aérea são INDEPENDENTES')\n",
    "\n",
    "# Dependendia do status do voo X DESTINO\n",
    "stat, pdest, dof, expected = chi2_contingency(dest_canc)\n",
    "print(\"valor-p do Destino é \"  + str(pdest))\n",
    "if pdest <= alpha:\n",
    "    print('Cancelamento e Destino são DEPENDENTES')\n",
    "else:\n",
    "    print('Cancelamento e Destino são INDEPENDENTES')\n",
    "\n",
    "# Dependendia do status do voo X ORIGEM\n",
    "stat, porg, dof, expected = chi2_contingency(org_canc)\n",
    "print(\"valor-p da Origem é \"  + str(porg))\n",
    "if porg <= alpha:\n",
    "    print('Cancelamento e Origem são DEPENDENTES')\n",
    "else:\n",
    "    print('Cancelamento Origem são INDEPENDENTES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando a Correlação nas variáveis quantitativas\n",
    "A Feature Distância é a nossa única variável quantitativa dentro da nossa análise e por isso é a única sobre a qual podemos aplicar o índice de correlação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_canc_dist = Dados_gerais['CANCELLED'].corr(Dados_gerais['DISTANCE'])\n",
    "print(f'A correlação entre o Cancelamento de Voos e Distância do voo = {corr_canc_dist}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Primeiras Conclusões\n",
    "\n",
    "A partir dos coeficientes de relação e dependência entre o nosso Target e suas Features, podemos chegar a alguma conclusões importantes que antecedem a conclusão do nosso modelo. \n",
    "\n",
    "Apenas as features de Destino e Origem se mostraram dependentes do Target, enquanto a Companhia Aérea se mostrou Independente. \n",
    "\n",
    "Já a Distância por ter um coeficiente de correlação com o Cancelamento < 1, podemos concluir que ambas as variáveis são inversamente proporcionais, mas ainda sim se influenciam. \n",
    "\n",
    "Com isso, optamos por seguir apenas com as features de Distância, Origem e Destino para a construção do nosso modelo de predição, uma vez que foram apenas essas as variáveis que se mostraram relevantes para o nosso parâmetro de interesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Montando os Modelos Preditivos\n",
    "Como estamos trabalhando com variáveis qualitativas e a construção de modelos preditivos trabalha melhor com quantitativas, precisamos primeiro suavizar o nosso dataframe qualitativa para poder inseri-lo mais facilmente em modelos de predição. \n",
    "\n",
    "E é isso que faremos no código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_gerais_00 = Dados_gerais \n",
    "Dados_gerais = Dados_gerais_00.sample(frac = 0.1)\n",
    "# Creating dataframe with\n",
    "# rest of the 50% values\n",
    "rest_Dados_gerais = Dados_gerais_00.drop(Dados_gerais.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "Dados_gerais = Dados_gerais.dropna()\n",
    "Dados_gerais.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['OP_CARRIER','ORIGIN', 'DEST']\n",
    "for var in cat_vars:\n",
    "    cat_list = 'var' + '_' + var\n",
    "    cat_list = pd.get_dummies(Dados_gerais[var],prefix = var)\n",
    "    Dados_gerais = Dados_gerais.join(cat_list)\n",
    "     \n",
    "data_vars=Dados_gerais.columns.values.tolist()\n",
    "to_keep=[i for i in data_vars if i not in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=Dados_gerais[to_keep]\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = len(data_final)\n",
    "col=726\n",
    "b=0\n",
    "while b < col:\n",
    "    if b<col:\n",
    "        nome = data_final.columns[b]\n",
    "        a = 0\n",
    "        sum = 0\n",
    "        while a<linhas:\n",
    "            sum+=data_final.iloc[a,b]\n",
    "            a+=1\n",
    "        \n",
    "        print(nome)\n",
    "        print(sum)\n",
    "        if sum < 20 and nome!= \"CANCELLED\":\n",
    "            data_final = data_final.drop(nome, axis=1)\n",
    "            b+=-1\n",
    "            col+=-1\n",
    "        b+=1\n",
    "        \n",
    "data_sem_zero = data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=data_sem_zero\n",
    "data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = len(data_final)\n",
    "col=54\n",
    "b=0\n",
    "while b < col:\n",
    "    if b<col:\n",
    "        nome = data_final.columns[b]\n",
    "        a = 0\n",
    "        sum = 0\n",
    "        while a<linhas:\n",
    "            sum+=data_final.iloc[a,b]\n",
    "            a+=1\n",
    "        print(sum)\n",
    "        if sum < 20 and nome!= \"CANCELLED\":\n",
    "            data_final = data_final.drop(nome, axis=1)\n",
    "            b+=-1\n",
    "            col+=-1\n",
    "        b+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aplicando o 1° Modelo: Regressão Logística\n",
    "Primeiro vamos aplicar o métedo do modelo de Regressão Logística.\n",
    "\n",
    "\n",
    "**`O que é Regressão Logística?`** Regressão logística é um dos tipos de Machine Learning classification algorithm e é usado para prever a probabilidade de uma variável categórica dependente. Nesse modelo a variável categórica é binária, ou seja, é correspondente a valores como 1 e 0. Por esse motivo, resolvemos adotar esse tipo de regressão para modelar o nosso problema, já que a nossa variável target é binária - Voo Cancelado (=1.0) // Voo Não Cancelado (0.0). \n",
    "\n",
    "Para isso iremos: nomear o Target e as Features, separar a nossa base de dados em dataframes de treino e de teste, utilizando a função direta para isso do sklearn. \n",
    "Sobre ela aplicar o modelo de Regressão Logística, também do sklearn, com a sua função direta. Assim teremos a previsão de acurácia do modelo, ao comparar os resultados obtidos pelo treino em cima do dataframe de teste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o Target das Features\n",
    "X = data_final.loc[:, data_final.columns != 'CANCELLED']\n",
    "y = data_final.loc[:, data_final.columns == 'CANCELLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y= os.fit_resample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['CANCELLED'])\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['CANCELLED']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['CANCELLED']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['CANCELLED']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['CANCELLED']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_vars=data_final.columns.values.tolist()\n",
    "y=['y']\n",
    "X=[i for i in data_final_vars if i not in y]\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, step = 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name_list=[]\n",
    "for i in range(len(rfe.support_)):\n",
    "    teste = rfe.support_[i]\n",
    "    nome = data_final.columns[i]\n",
    "    if teste == True:\n",
    "        Name_list.append(nome)\n",
    "X=os_data_X[Name_list]\n",
    "y=os_data_y['CANCELLED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit(method='bfgs')\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Acurácia do Nosso Classificador de Regressão Logística sobre o df de teste: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "certos=confusion_matrix[0][0]+confusion_matrix[1][1]\n",
    "errados=confusion_matrix[0][1]+confusion_matrix[1][0]\n",
    "print(confusion_matrix)\n",
    "\n",
    "print(f'Temos {certos} predições certas')\n",
    "print(f'Temos {errados} predições erradas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Relatório de Classificação do Nosso Modelo:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gráfico de Curva ROC e AUC')\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados do Modelo de Regressão Logística\n",
    "- Acurácia final da Previsão do Modelo: 92%\n",
    "- Gráfico de Curva ROC e AUC: Esse tipo de gráfico plota a Curva ROC, a qual demonstra desempenho de um modelo de classificação seus limiares de classificação, representando os parâmetros das taxas de verdadeiro e falsos positivos sobre a predição. A área sob a curva ROC representa o AUC, a qual representa o desempenho em todos os limites de classificação possíveis, sendo assim equivalente a acurácia de previsão do modelo, no nosso caso, sendo assim AUC = 0.92.\n",
    "\n",
    "### Conclusão\n",
    "Nosso modelo está adequado, uma vez que ele possui uma alta taxa de acurácia, provando uma alta qualidade de previsão para ele. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aplicando o 2° Modelo: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final ['CANCELLED'].cat.categories=['Não cancelado', 'Cancelado']\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = data_final.loc[:, data_final.columns != 'CANCELLED']\n",
    "y = data_final.loc[:, data_final.columns == 'CANCELLED']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.7, \n",
    "                                                    random_state=SEED)\n",
    "\n",
    "                                                    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=3, \n",
    "                             max_depth=2,\n",
    "                             random_state=SEED)\n",
    "\n",
    "# Fit RandomForestClassifier\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set labels\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "features = X.columns.values # The name of each column\n",
    "classes = ['Não Cancelado', 'Cancelado'] # The name of each class\n",
    "\n",
    "\n",
    "for estimator in rfc.estimators_:\n",
    "    print(estimator)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    tree.plot_tree(estimator,\n",
    "                   feature_names=features,\n",
    "                   class_names=classes,\n",
    "                   fontsize=8, \n",
    "                   filled=True, \n",
    "                   rounded=True)\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d').set_title('Seu vôo ser cancelado confusion matrix (0 = Não cancelado, 1 = Cancelado')\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aplicando o 3° Modelo: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linhas = len(data_final)\n",
    "colunas = len(data_final.columns)\n",
    "col= colunas\n",
    "tamanho = []\n",
    "b=0\n",
    "while b < col:\n",
    "    if b<col:\n",
    "        nome = data_final.columns[b]\n",
    "        if nome != 'CANCELLED':\n",
    "            tamanho.append(nome)\n",
    "    b+=1\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "X = data_final.loc[:, data_final.columns != 'CANCELLED']\n",
    "y = data_final.loc[:, data_final.columns == 'CANCELLED']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Referências \n",
    "\n",
    "- https://acervolima.com/python-teste-qui-quadrado-de-pearson/\n",
    "- https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8\n",
    "- https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07b9bce58800e0c6bedceed095b1f0040fd5a37e90a2446371ba89fcb226324d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
